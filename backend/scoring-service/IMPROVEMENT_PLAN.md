# üìà Plan d'Am√©lioration des Mod√®les

## ‚úÖ Ce qui a √©t√© fait

1. ‚úÖ Mod√®les entra√Æn√©s avec donn√©es synth√©tiques (baseline)
2. ‚úÖ Mod√®les entra√Æn√©s avec donn√©es r√©elles Open Food Facts (1,988 produits)
3. ‚úÖ Scripts d'entra√Ænement cr√©√©s
4. ‚úÖ Service op√©rationnel avec mod√®les charg√©s

## ‚ö†Ô∏è Limitations actuelles

### Performance actuelle
- **Classification** : 34% accuracy (cible: >70%)
- **R√©gression** : R¬≤ = 0.03 (cible: >0.60)

### Causes principales
1. **Features LCA estim√©es** : Utilisation d'heuristiques au lieu du vrai LCA Service
2. **Features NLP simplifi√©es** : Extraction basique au lieu du vrai NLP Service
3. **Donn√©es limit√©es** : Seulement 1,988 √©chantillons

## üéØ Plan d'am√©lioration

### Phase 1 : Am√©liorer l'extraction de features (Priorit√© 1)

**Objectif** : Utiliser les vrais services pour extraire les features

**Actions** :
1. Modifier `train_with_real_data.py` pour appeler les vrais services
2. Pour chaque produit :
   - Appeler NLP Service avec `ingredients_text`
   - Appeler LCA Service avec les ingr√©dients extraits
   - Utiliser les vraies donn√©es pour entra√Æner

**Code √† ajouter** :
```python
async def extract_features_with_real_services(self, product):
    async with httpx.AsyncClient() as client:
        # NLP Service
        nlp_response = await client.post(
            f"{self.nlp_url}/nlp/extract",
            json={"text": product['ingredients_text']}
        )
        nlp_data = nlp_response.json()
        
        # LCA Service
        ingredients_for_lca = [
            {"name": ing["text"], "quantity_percentage": None}
            for ing in nlp_data.get("ingredients", [])
        ]
        
        lca_response = await client.post(
            f"{self.lca_url}/lca/calc",
            json={
                "ingredients": ingredients_for_lca,
                "packaging": {"type": nlp_data.get("packaging_type")},
                "product_weight_kg": 1.0
            }
        )
        lca_data = lca_response.json()
        
        # Extraire features
        return self._prepare_features(lca_data, nlp_data)
```

**R√©sultat attendu** : R¬≤ > 0.50, Accuracy > 60%

---

### Phase 2 : Collecter plus de donn√©es (Priorit√© 2)

**Objectif** : Augmenter le dataset √† 10,000+ produits

**Actions** :
1. Scraper plus de produits Open Food Facts
2. Filtrer ceux avec `ecoscore_grade` valide
3. R√©-entra√Æner avec plus de donn√©es

**Commandes** :
```bash
cd data-pipeline
python 1_scrapers/openfoodfacts_scraper.py  # Scraper 10K+ produits
python 2_cleaning/normalizer.py
```

**R√©sultat attendu** : Meilleure g√©n√©ralisation

---

### Phase 3 : Fine-tuning des hyperparam√®tres (Priorit√© 3)

**Objectif** : Optimiser les hyperparam√®tres des mod√®les

**Actions** :
1. Utiliser `GridSearchCV` pour trouver les meilleurs param√®tres
2. Tester diff√©rentes configurations :
   - `n_estimators`: [50, 100, 200, 300]
   - `max_depth`: [5, 10, 15, 20]
   - `min_samples_split`: [2, 5, 10]

**Code** :
```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 15, 20],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(
    RandomForestClassifier(class_weight='balanced'),
    param_grid,
    cv=5,
    scoring='f1_macro'
)
grid_search.fit(X_train, y_train)
```

**R√©sultat attendu** : +5-10% de performance

---

### Phase 4 : Validation et tests (Priorit√© 4)

**Objectif** : Valider les mod√®les sur des produits r√©els

**Actions** :
1. Cr√©er un dataset de test avec produits r√©els
2. Comparer les pr√©dictions avec les vrais scores
3. Analyser les erreurs
4. Ajuster si n√©cessaire

---

## üìä M√©triques de succ√®s

| M√©trique | Actuel | Cible Phase 1 | Cible Final |
|----------|--------|---------------|-------------|
| Classification Accuracy | 34% | 60% | 75% |
| Classification F1 | 0.34 | 0.60 | 0.75 |
| R√©gression R¬≤ | 0.03 | 0.50 | 0.70 |
| R√©gression RMSE | 28.37 | 20 | 15 |

---

## üöÄ Quick Start pour am√©liorer

### √âtape 1 : Utiliser les vrais services

```bash
# Modifier train_with_real_data.py pour appeler les services
# Puis r√©-entra√Æner
docker-compose exec scoring-service python -c "
from app.services.train_with_real_data import RealDataTrainer
trainer = RealDataTrainer()
trainer.train_with_real_data('/tmp/products_cleaned.csv', max_samples=3000)
"
```

### √âtape 2 : Collecter plus de donn√©es

```bash
cd data-pipeline
python 1_scrapers/openfoodfacts_scraper.py  # Augmenter max_products √† 10000
```

### √âtape 3 : R√©-entra√Æner

```bash
docker-compose exec scoring-service python -c "
from app.services.train_with_real_data import RealDataTrainer
trainer = RealDataTrainer()
trainer.train_with_real_data('/tmp/products_cleaned.csv', max_samples=5000)
"
```

---

## üí° Notes importantes

- Les mod√®les actuels fonctionnent mais peuvent √™tre am√©lior√©s
- L'utilisation des vrais services (NLP + LCA) am√©liorera significativement les performances
- Plus de donn√©es = meilleure g√©n√©ralisation
- Les hyperparam√®tres peuvent √™tre optimis√©s avec GridSearchCV

---

## üìù Prochaines actions recommand√©es

1. **Imm√©diat** : Modifier `train_with_real_data.py` pour utiliser les vrais services
2. **Court terme** : Collecter 10K+ produits
3. **Moyen terme** : Fine-tuning des hyperparam√®tres
4. **Long terme** : Validation continue avec nouveaux produits

