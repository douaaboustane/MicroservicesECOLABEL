"""
Script principal de preprocessing
Orchestre toutes les Ã©tapes de prÃ©paration des donnÃ©es pour le ML
"""
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))

from utils.logger import log
from tokenizer import tokenize_ingredients
from auto_annotator import create_ner_annotations
from train_test_splitter import split_annotations


def main():
    """ExÃ©cute le pipeline de preprocessing complet"""
    log.info("=" * 60)
    log.info("âš™ï¸  DÃ‰MARRAGE DU PREPROCESSING")
    log.info("=" * 60)
    
    # Ã‰tape 1: Tokenisation
    log.info("\nğŸ“ Ã‰tape 1/3: Tokenisation")
    tokenize_ingredients(
        "datasets/cleaned/products_cleaned.csv",
        "datasets/preprocessed/products_tokenized.csv"
    )
    
    # Ã‰tape 2: Auto-annotation NER
    log.info("\nğŸ·ï¸  Ã‰tape 2/3: Auto-annotation NER")
    create_ner_annotations(
        "datasets/preprocessed/products_tokenized.csv",
        "datasets/preprocessed/ner_annotations.jsonl",
        sample_size=1000
    )
    
    # Ã‰tape 3: SÃ©paration train/val/test
    log.info("\nâœ‚ï¸  Ã‰tape 3/3: SÃ©paration train/val/test")
    split_annotations(
        "datasets/preprocessed/ner_annotations.jsonl",
        "datasets/preprocessed/splits",
        test_size=0.15,
        val_size=0.15,
        random_seed=42
    )
    
    log.info("\n" + "=" * 60)
    log.info("âœ… PREPROCESSING TERMINÃ‰ AVEC SUCCÃˆS")
    log.info("=" * 60)
    log.info("\nğŸ“ Fichiers gÃ©nÃ©rÃ©s:")
    log.info("   - datasets/preprocessed/products_tokenized.csv")
    log.info("   - datasets/preprocessed/ner_annotations.jsonl")
    log.info("   - datasets/preprocessed/splits/train.jsonl")
    log.info("   - datasets/preprocessed/splits/validation.jsonl")
    log.info("   - datasets/preprocessed/splits/test.jsonl")
    log.info("\nğŸš€ PrÃªt pour l'entraÃ®nement du modÃ¨le NER !")


if __name__ == "__main__":
    main()

